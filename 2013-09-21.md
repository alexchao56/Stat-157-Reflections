This week, we were fortunate to have ecologist Eric Berlow join us to discuss some of his work and how collaborative data science has been and will continue to be an integral part of his work. Berlow, an ecologist and senior TED fellow, has studied the interconnectedness of ecosystems with climiate change, government, coporations and others while specializing in network science. 

Specifically, Eric talked about his study of toad meadows in the yosemite mountains. Whereas many of the data problems now have to do with "big data" and problems that are incredibly difficult to scale, Eric and others in his field face the problem of inferring from very limited datasets. A lot of the data that he and his team collects come from surveys and expeditions in which people go out and look for areas that toads can be found. They also have cabinets full of paper surveys that need to be entered into a database to provide as comprehensive of a data source as possible. 

What was most interesting from his analysis, was the impact that his work had on other fields of study like genetics, climate change, business and others. By performing network analysis and detecting otspots of breeding meadows, isolated meadows, and meadows with high-deletion impact, Eric is able to address such questions as "What should management priority be?" and "Do horses have a negative impact on toads?" 

An important distinction that Eric and Professor Stark made during class was the fact that there are many stories concerning this topic of interest, but no data; or as Stark succintly put it, "The plural of anecdoteis not data." Thus, the main statistical problem that had to be addressed was how do you find causality with observational data? Eric pointed out that this is the same problem that big data has to face, namely that there is a whole plethora of observations but they are not yet framed in such a way as to be useful. 

On Thursday, Stark in his lecture went over more of the statistical techniques that go into data science, especially the ones we will be using for our capstone project on earthquake prediction.


We discussed such things as:
- [T-tests](http://en.wikipedia.org/wiki/Student's_t-test)
- [Non-parametric tests](http://en.wikipedia.org/wiki/Non-parametric_statistics)
- [The Likert Scale](http://en.wikipedia.org/wiki/Likert_scale)
- [Stochastic Models](http://en.wikipedia.org/wiki/Stochastic_Models)
- [Poisson Process](http://en.wikipedia.org/wiki/Poisson_process)
- and many more!

With these statistical technieques and the tools at our disposal we'll be looking at how accurate are a person's metric for predicting earthquakes. 

Some of the claimed precursors of earthquakes include:
- foreshocks and patterns
- electromagnetics
- cloud formations
- infrared
- well water composition, temperature and level
- geodetics
- animal behavior

After Professor Stark's lecture, I realized that even though I am a statistics major, there were still many more things that I had to review and learn in order for my analyses to be robust and sound. Looking toward next week, I anticipate that we'll begin doing more statistics and programming. I can't wait. 
